"Higher level section"_Build.html - "LAMMPS WWW Site"_lws - "LAMMPS
Documentation"_ld - "LAMMPS Commands"_lc :c

:link(lws,http://lammps.sandia.gov)
:link(ld,Manual.html)
:link(lc,Commands_all.html)

:line

Packages with extra build options :h3

When building with some packages, additional steps may be required,
in addition to:

-D PKG_NAME=yes    # CMake
make yes-name      # make :pre

as described on the "Build_package"_Build_package.html doc page.

For a CMake build there may be additional optional or required
variables to set.  For a build with make, a provided library under the
lammps/lib directory may need to be built first.  Or an external
library may need to exist on your system or be downloaded and built.
You may need to tell LAMMPS where it is found on your system.

This is the list of packages that may require additional steps.

"COMPRESS"_#compress,
"GPU"_#gpu,
"KIM"_#kim,
"KOKKOS"_#kokkos,
"LATTE"_#latte,
"MESSAGE"_#message,
"MSCG"_#mscg,
"OPT"_#opt,
"POEMS"_#poems,
"PYTHON"_#python,
"VORONOI"_#voronoi,
"USER-ADIOS"_#user-adios,
"USER-ATC"_#user-atc,
"USER-AWPMD"_#user-awpmd,
"USER-COLVARS"_#user-colvars,
"USER-H5MD"_#user-h5md,
"USER-INTEL"_#user-intel,
"USER-MOLFILE"_#user-molfile,
"USER-NETCDF"_#user-netcdf,
"USER-PLUMED"_#user-plumed,
"USER-OMP"_#user-omp,
"USER-QMMM"_#user-qmmm,
"USER-QUIP"_#user-quip,
"USER-SCAFACOS"_#user-scafacos,
"USER-SMD"_#user-smd,
"USER-VTK"_#user-vtk :tb(c=6,ea=c,a=l)

:line

COMPRESS package :h4,link(compress)

To build with this package you must have the zlib compression library
available on your system.

[CMake build]:

If CMake cannot find the library, you can set these variables:

-D ZLIB_INCLUDE_DIR=path    # path to zlib.h header file
-D ZLIB_LIBRARIES=path      # path to libz.a (.so) file :pre

[Traditional make]:

If make cannot find the library, you can edit the
lib/compress/Makefile.lammps file to specify the paths and library
name.

:line

GPU package :h4,link(gpu)

To build with this package, you must choose options for precision and
which GPU hardware to build for.

[CMake build]:

-D GPU_API=value          # value = opencl (default) or cuda
-D GPU_PREC=value         # precision setting
                          # value = double or mixed (default) or single
-D OCL_TUNE=value         # hardware choice for GPU_API=opencl
                          # generic (default) or intel (Intel CPU) or fermi, kepler, cypress (NVIDIA)
-D GPU_ARCH=value         # primary GPU hardware choice for GPU_API=cuda
                          # value = sm_XX, see below
                          # default is sm_30
-D CUDPP_OPT=value        # optimization setting for GPU_API=cuda
                          # enables CUDA Performance Primitives Optimizations
                          # value = yes (default) or no
-D CUDA_MPS_SUPPORT=value # enables some tweaks required to run with active nvidia-cuda-mps daemon
                          # value = yes or no (default) :pre

GPU_ARCH settings for different GPU hardware is as follows:

sm_12 or sm_13 for GT200 (supported by CUDA 3.2 until CUDA 6.5)
sm_20 or sm_21 for Fermi (supported by CUDA 3.2 until CUDA 7.5)
sm_30 or sm_35 or sm_37 for Kepler (supported since CUDA 5)
sm_50 or sm_52 for Maxwell (supported since CUDA 6)
sm_60 or sm_61 for Pascal (supported since CUDA 8)
sm_70 for Volta (supported since CUDA 9)
sm_75 for Turing (supported since CUDA 10) :ul

A more detailed list can be found, for example,
at "Wikipedia's CUDA article"_https://en.wikipedia.org/wiki/CUDA#GPUs_supported

CMake can detect which version of the CUDA toolkit is used and thus can
include support for [all] major GPU architectures supported by this toolkit.
Thus the GPU_ARCH setting is merely an optimization, to have code for
the preferred GPU architecture directly included rather than having to wait
for the JIT compiler of the CUDA driver to translate it.

[Traditional make]:

Before building LAMMPS, you must build the GPU library in lib/gpu.
You can do this manually if you prefer; follow the instructions in
lib/gpu/README.  Note that the GPU library uses MPI calls, so you must
use the same MPI library (or the STUBS library) settings as the main
LAMMPS code.  This also applies to the -DLAMMPS_BIGBIG,
-DLAMMPS_SMALLBIG, or -DLAMMPS_SMALLSMALL settings in whichever
Makefile you use.

You can also build the library in one step from the lammps/src dir,
using a command like these, which simply invoke the lib/gpu/Install.py
script with the specified args:

make lib-gpu               # print help message
make lib-gpu args="-b"     # build GPU library with default Makefile.linux
make lib-gpu args="-m xk7 -p single -o xk7.single"  # create new Makefile.xk7.single, altered for single-precision
make lib-gpu args="-m mpi -a sm_60 -p mixed -b" # build GPU library with mixed precision and P100 using other settings in Makefile.mpi :pre

Note that this procedure starts with a Makefile.machine in lib/gpu, as
specified by the "-m" switch.  For your convenience, machine makefiles
for "mpi" and "serial" are provided, which have the same settings as
the corresponding machine makefiles in the main LAMMPS source
folder. In addition you can alter 4 important settings in the
Makefile.machine you start from via the corresponding -c, -a, -p, -e
switches (as in the examples above), and also save a copy of the new
Makefile if desired:

CUDA_HOME = where NVIDIA CUDA software is installed on your system
CUDA_ARCH = sm_XX, what GPU hardware you have, same as CMake GPU_ARCH above
CUDA_PRECISION = precision (double, mixed, single)
EXTRAMAKE = which Makefile.lammps.* file to copy to Makefile.lammps :ul

The file Makefile.linux_multi is set up to include support for multiple
GPU architectures as supported by the CUDA toolkit in use. This is done
through using the "--gencode " flag, which can be used multiple times and
thus support all GPU architectures supported by your CUDA compiler.

If the library build is successful, 3 files should be created:
lib/gpu/libgpu.a, lib/gpu/nvc_get_devices, and
lib/gpu/Makefile.lammps.  The latter has settings that enable LAMMPS
to link with CUDA libraries.  If the settings in Makefile.lammps for
your machine are not correct, the LAMMPS build will fail, and
lib/gpu/Makefile.lammps may need to be edited.

NOTE: If you re-build the GPU library in lib/gpu, you should always
un-install the GPU package in lammps/src, then re-install it and
re-build LAMMPS.  This is because the compilation of files in the GPU
package uses the library settings from the lib/gpu/Makefile.machine
used to build the GPU library.


:line

KIM package :h4,link(kim)

To build with this package, the KIM library with API v2 must be downloaded
and built on your system.  It must include the KIM models that you want to
use with LAMMPS. If you want to use the "kim_query"_kim_commands.html
command, you also need to have libcurl installed with the matching
development headers and the curl-config tool.

See "Obtaining KIM Models"_http://openkim.org/doc/usage/obtaining-models to
learn how to install a pre-build binary of the OpenKIM Repository of Models.
See the list of all KIM models here: https://openkim.org/browse/models

(Also note that when downloading and installing from source
the KIM API library with all its models, may take a long time (tens of
minutes to hours) to build.  Of course you only need to do that once.)

[CMake build]:

-D DOWNLOAD_KIM=value           # download OpenKIM API v2 for build, value = no (default) or yes :pre

If DOWNLOAD_KIM is set, the KIM library will be downloaded and built
inside the CMake build directory.  If the KIM library is already on
your system (in a location CMake cannot find it), set the PKG_CONFIG_PATH
environment variable so that libkim-api can be found.

[Traditional make]:

You can download and build the KIM library manually if you prefer;
follow the instructions in lib/kim/README.  You can also do it in one
step from the lammps/src dir, using a command like these, which simply
invoke the lib/kim/Install.py script with the specified args.

make lib-kim              # print help message
make lib-kim args="-b "   # (re-)install KIM API lib with only example models
make lib-kim args="-b -a Glue_Ercolessi_Adams_Al__MO_324507536345_001"  # ditto plus one model
make lib-kim args="-b -a everything"     # install KIM API lib with all models
make lib-kim args="-n -a EAM_Dynamo_Ackland_W__MO_141627196590_002"       # add one model or model driver
make lib-kim args="-p /usr/local" # use an existing KIM API installation at the provided location
make lib-kim args="-p /usr/local -a EAM_Dynamo_Ackland_W__MO_141627196590_002" # ditto but add one model or driver :pre

:line

KOKKOS package :h4,link(kokkos)

To build with this package, you must choose which hardware you want to
build for, either CPUs (multi-threading via OpenMP) or KNLs (OpenMP)
or GPUs (NVIDIA Cuda).

For a CMake or make build, these are the possible choices for the
KOKKOS_ARCH settings described below.  Note that for CMake, these are
really Kokkos variables, not LAMMPS variables.  Hence you must use
case-sensitive values, e.g. BDW, not bdw.

ARMv80 = ARMv8.0 Compatible CPU
ARMv81 = ARMv8.1 Compatible CPU
ARMv8-ThunderX = ARMv8 Cavium ThunderX CPU
BGQ = IBM Blue Gene/Q CPUs
Power8 = IBM POWER8 CPUs
Power9 = IBM POWER9 CPUs
SNB = Intel Sandy/Ivy Bridge CPUs
HSW = Intel Haswell CPUs
BDW = Intel Broadwell Xeon E-class CPUs
SKX = Intel Sky Lake Xeon E-class HPC CPUs (AVX512)
KNC = Intel Knights Corner Xeon Phi
KNL = Intel Knights Landing Xeon Phi
Kepler30 = NVIDIA Kepler generation CC 3.0
Kepler32 = NVIDIA Kepler generation CC 3.2
Kepler35 = NVIDIA Kepler generation CC 3.5
Kepler37 = NVIDIA Kepler generation CC 3.7
Maxwell50 = NVIDIA Maxwell generation CC 5.0
Maxwell52 = NVIDIA Maxwell generation CC 5.2
Maxwell53 = NVIDIA Maxwell generation CC 5.3
Pascal60 = NVIDIA Pascal generation CC 6.0
Pascal61 = NVIDIA Pascal generation CC 6.1
Volta70 = NVIDIA Volta generation CC 7.0
Volta72 = NVIDIA Volta generation CC 7.2
Turing75 = NVIDIA Turing generation CC 7.5 :ul

[CMake build]:

For multicore CPUs using OpenMP, set these 2 variables.

-D KOKKOS_ARCH=archCPU         # archCPU = CPU from list above
-D KOKKOS_ENABLE_OPENMP=yes :pre

For Intel KNLs using OpenMP, set these 2 variables:

-D KOKKOS_ARCH=KNL
-D KOKKOS_ENABLE_OPENMP=yes :pre

For NVIDIA GPUs using CUDA, set these 4 variables:

-D KOKKOS_ARCH="archCPU;archGPU"   # archCPU = CPU from list above that is hosting the GPU
                                   # archGPU = GPU from list above
-D KOKKOS_ENABLE_CUDA=yes
-D KOKKOS_ENABLE_OPENMP=yes
-D CMAKE_CXX_COMPILER=wrapper      # wrapper = full path to Cuda nvcc wrapper :pre

The wrapper value is the Cuda nvcc compiler wrapper provided in the
Kokkos library: lib/kokkos/bin/nvcc_wrapper.  The setting should
include the full path name to the wrapper, e.g.

-D CMAKE_CXX_COMPILER=/home/username/lammps/lib/kokkos/bin/nvcc_wrapper :pre

[Traditional make]:

Choose which hardware to support in Makefile.machine via
KOKKOS_DEVICES and KOKKOS_ARCH settings.  See the
src/MAKE/OPTIONS/Makefile.kokkos* files for examples.

For multicore CPUs using OpenMP:

KOKKOS_DEVICES = OpenMP
KOKKOS_ARCH = archCPU      # archCPU = CPU from list above :pre

For Intel KNLs using OpenMP:

KOKKOS_DEVICES = OpenMP
KOKKOS_ARCH = KNL :pre

For NVIDIA GPUs using CUDA:

KOKKOS_DEVICES = Cuda
KOKKOS_ARCH = archCPU,archGPU    # archCPU = CPU from list above that is hosting the GPU
                                 # archGPU = GPU from list above :pre

For GPUs, you also need these 2 lines in your Makefile.machine before
the CC line is defined, in this case for use with OpenMPI mpicxx.  The
2 lines define a nvcc wrapper compiler, which will use nvcc for
compiling CUDA files and use a C++ compiler for non-Kokkos, non-CUDA
files.

KOKKOS_ABSOLUTE_PATH = $(shell cd $(KOKKOS_PATH); pwd)
export OMPI_CXX = $(KOKKOS_ABSOLUTE_PATH)/config/nvcc_wrapper
CC =            mpicxx :pre

:line

LATTE package :h4,link(latte)

To build with this package, you must download and build the LATTE
library.

[CMake build]:

-D DOWNLOAD_LATTE=value    # download LATTE for build, value = no (default) or yes
-D LATTE_LIBRARY=path      # LATTE library file (only needed if a custom location) :pre

If DOWNLOAD_LATTE is set, the LATTE library will be downloaded and
built inside the CMake build directory.  If the LATTE library is
already on your system (in a location CMake cannot find it),
LATTE_LIBRARY is the filename (plus path) of the LATTE library file,
not the directory the library file is in.

[Traditional make]:

You can download and build the LATTE library manually if you prefer;
follow the instructions in lib/latte/README.  You can also do it in
one step from the lammps/src dir, using a command like these, which
simply invokes the lib/latte/Install.py script with the specified
args:

make lib-latte                          # print help message
make lib-latte args="-b"                # download and build in lib/latte/LATTE-master
make lib-latte args="-p $HOME/latte"    # use existing LATTE installation in $HOME/latte
make lib-latte args="-b -m gfortran"    # download and build in lib/latte and
                                        #   copy Makefile.lammps.gfortran to Makefile.lammps
:pre

Note that 3 symbolic (soft) links, "includelink" and "liblink" and
"filelink.o", are created in lib/latte to point into the LATTE home
dir.  When LAMMPS itself is built it will use these links.  You should
also check that the Makefile.lammps file you create is appropriate for
the compiler you use on your system to build LATTE.

:line

MESSAGE package :h4,link(message)

This package can optionally include support for messaging via sockets,
using the open-source "ZeroMQ library"_http://zeromq.org, which must
be installed on your system.

[CMake build]:

-D MESSAGE_ZMQ=value    # build with ZeroMQ support, value = no (default) or yes
-D ZMQ_LIBRARY=path     # ZMQ library file (only needed if a custom location)
-D ZMQ_INCLUDE_DIR=path # ZMQ include directory (only needed if a custom location)
:pre

[Traditional make]:

Before building LAMMPS, you must build the CSlib library in
lib/message.  You can build the CSlib library manually if you prefer;
follow the instructions in lib/message/README.  You can also do it in
one step from the lammps/src dir, using a command like these, which
simply invoke the lib/message/Install.py script with the specified args:

make lib-message               # print help message
make lib-message args="-m -z"  # build with MPI and socket (ZMQ) support
make lib-message args="-s"     # build as serial lib with no ZMQ support
:pre

The build should produce two files: lib/message/cslib/src/libmessage.a
and lib/message/Makefile.lammps.  The latter is copied from an
existing Makefile.lammps.* and has settings to link with the ZeroMQ
library if requested in the build.

:line

MSCG package :h4,link(mscg)

To build with this package, you must download and build the MS-CG
library.  Building the MS-CG library and using it from LAMMPS requires
a C++11 compatible compiler and that the GSL (GNU Scientific Library)
headers and libraries are installed on your machine.  See the
lib/mscg/README and MSCG/Install files for more details.

[CMake build]:

-D DOWNLOAD_MSCG=value    # download MSCG for build, value = no (default) or yes
-D MSCG_LIBRARY=path      # MSCG library file (only needed if a custom location)
-D MSCG_INCLUDE_DIR=path  # MSCG include directory (only needed if a custom location) :pre

If DOWNLOAD_MSCG is set, the MSCG library will be downloaded and built
inside the CMake build directory.  If the MSCG library is already on
your system (in a location CMake cannot find it), MSCG_LIBRARY is the
filename (plus path) of the MSCG library file, not the directory the
library file is in.  MSCG_INCLUDE_DIR is the directory the MSCG
include file is in.

[Traditional make]:

You can download and build the MS-CG library manually if you prefer;
follow the instructions in lib/mscg/README.  You can also do it in one
step from the lammps/src dir, using a command like these, which simply
invoke the lib/mscg/Install.py script with the specified args:

make lib-mscg             # print help message
make lib-mscg args="-b -m serial"   # download and build in lib/mscg/MSCG-release-master
                                    # with the settings compatible with "make serial"
make lib-mscg args="-b -m mpi"      # download and build in lib/mscg/MSCG-release-master
                                    # with the settings compatible with "make mpi"
make lib-mscg args="-p /usr/local/mscg-release" # use the existing MS-CG installation in /usr/local/mscg-release :pre

Note that 2 symbolic (soft) links, "includelink" and "liblink", will
be created in lib/mscg to point to the MS-CG src/installation dir.
When LAMMPS is built in src it will use these links.  You should not
need to edit the lib/mscg/Makefile.lammps file.

:line

OPT package :h4,link(opt)

[CMake build]:

No additional settings are needed besides "-D PKG_OPT=yes".

[Traditional make]:

The compile flag "-restrict" must be used to build LAMMPS with the OPT
package when using Intel compilers.  It should be added to the CCFLAGS
line of your Makefile.machine.  See src/MAKE/OPTIONS/Makefile.opt for
an example.

:line

POEMS package :h4,link(poems)

[CMake build]:

No additional settings are needed besides "-D PKG_OPT=yes".

[Traditional make]:

Before building LAMMPS, you must build the POEMS library in lib/poems.
You can do this manually if you prefer; follow the instructions in
lib/poems/README.  You can also do it in one step from the lammps/src
dir, using a command like these, which simply invoke the
lib/poems/Install.py script with the specified args:

make lib-poems                   # print help message
make lib-poems args="-m serial"  # build with GNU g++ compiler (settings as with "make serial")
make lib-poems args="-m mpi"     # build with default MPI C++ compiler (settings as with "make mpi")
make lib-poems args="-m icc"     # build with Intel icc compiler :pre

The build should produce two files: lib/poems/libpoems.a and
lib/poems/Makefile.lammps.  The latter is copied from an existing
Makefile.lammps.* and has settings needed to build LAMMPS with the
POEMS library (though typically the settings are just blank).  If
necessary, you can edit/create a new lib/poems/Makefile.machine file
for your system, which should define an EXTRAMAKE variable to specify
a corresponding Makefile.lammps.machine file.

:line

PYTHON package :h4,link(python)

Building with the PYTHON package requires you have a Python shared
library available on your system, which needs to be a Python 2
version, 2.6 or later.  Python 3 is not yet supported.  See
lib/python/README for more details.

[CMake build]:

-D PYTHON_EXECUTABLE=path   # path to Python executable to use :pre

Without this setting, CMake will guess the default Python on your
system.  To use a different Python version, you can either create a
virtualenv, activate it and then run cmake.  Or you can set the
PYTHON_EXECUTABLE variable to specify which Python interpreter should
be used.  Note note that you will also need to have the development
headers installed for this version, e.g. python2-devel.

[Traditional make]:

The build uses the lib/python/Makefile.lammps file in the compile/link
process to find Python.  You should only need to create a new
Makefile.lammps.* file (and copy it to Makefile.lammps) if the LAMMPS
build fails.

:line

VORONOI package :h4,link(voronoi)

To build with this package, you must download and build the "Voro++
library"_voro-home.

:link(voro-home,http://math.lbl.gov/voro++)

[CMake build]:

-D DOWNLOAD_VORO=value    # download Voro++ for build, value = no (default) or yes
-D VORO_LIBRARY=path      # Voro++ library file (only needed if at custom location)
-D VORO_INCLUDE_DIR=path  # Voro++ include directory (only needed if at custom location) :pre

If DOWNLOAD_VORO is set, the Voro++ library will be downloaded and
built inside the CMake build directory.  If the Voro++ library is
already on your system (in a location CMake cannot find it),
VORO_LIBRARY is the filename (plus path) of the Voro++ library file,
not the directory the library file is in.  VORO_INCLUDE_DIR is the
directory the Voro++ include file is in.

[Traditional make]:

You can download and build the Voro++ library manually if you prefer;
follow the instructions in lib/voronoi/README.  You can also do it in
one step from the lammps/src dir, using a command like these, which
simply invoke the lib/voronoi/Install.py script with the specified
args:

make lib-voronoi                          # print help message
make lib-voronoi args="-b"                # download and build the default version in lib/voronoi/voro++-<version>
make lib-voronoi args="-p $HOME/voro++"   # use existing Voro++ installation in $HOME/voro++
make lib-voronoi args="-b -v voro++0.4.6" # download and build the 0.4.6 version in lib/voronoi/voro++-0.4.6 :pre

Note that 2 symbolic (soft) links, "includelink" and "liblink", are
created in lib/voronoi to point to the Voro++ src dir.  When LAMMPS
builds in src it will use these links.  You should not need to edit
the lib/voronoi/Makefile.lammps file.

:line

USER-ADIOS package :h4,link(user-adios)

The USER-ADIOS package requires the "ADIOS I/O library"_https://github.com/ornladios/ADIOS2,
version 2.3.1 or newer. Make sure that you have ADIOS built either with or
without MPI to match if you build LAMMPS with or without MPI.
ADIOS compilation settings for LAMMPS are automatically detected, if the PATH
and LD_LIBRARY_PATH environment variables have been updated for the local ADIOS
installation and the instructions below are followed for the respective build systems.

[CMake build]:

-D ADIOS2_DIR=path        # path is where ADIOS 2.x is installed
-D PKG_USER-ADIOS=yes     :pre

[Traditional make]:

Turn on the USER-ADIOS package before building LAMMPS. If the ADIOS 2.x software is installed in PATH, there is nothing else to do:

make yes-user-adios                       :pre

otherwise, set ADIOS2_DIR environment variable when turning on the package:

ADIOS2_DIR=path make yes-user-adios   # path is where ADIOS 2.x is installed :pre

:line

USER-ATC package :h4,link(user-atc)

The USER-ATC package requires the MANYBODY package also be installed.

[CMake build]:

No additional settings are needed besides "-D PKG_USER-ATC=yes"
and "-D PKG_MANYBODY=yes".

[Traditional make]:

Before building LAMMPS, you must build the ATC library in lib/atc.
You can do this manually if you prefer; follow the instructions in
lib/atc/README.  You can also do it in one step from the lammps/src
dir, using a command like these, which simply invoke the
lib/atc/Install.py script with the specified args:

make lib-atc                      # print help message
make lib-atc args="-m serial"     # build with GNU g++ compiler and MPI STUBS (settings as with "make serial")
make lib-atc args="-m mpi"        # build with default MPI compiler (settings as with "make mpi")
make lib-atc args="-m icc"        # build with Intel icc compiler :pre

The build should produce two files: lib/atc/libatc.a and
lib/atc/Makefile.lammps.  The latter is copied from an existing
Makefile.lammps.* and has settings needed to build LAMMPS with the ATC
library.  If necessary, you can edit/create a new
lib/atc/Makefile.machine file for your system, which should define an
EXTRAMAKE variable to specify a corresponding Makefile.lammps.machine
file.

Note that the Makefile.lammps file has settings for the BLAS and
LAPACK linear algebra libraries.  As explained in lib/atc/README these
can either exist on your system, or you can use the files provided in
lib/linalg.  In the latter case you also need to build the library in
lib/linalg with a command like these:

make lib-linalg                     # print help message
make lib-linalg args="-m serial"    # build with GNU Fortran compiler (settings as with "make serial")
make lib-linalg args="-m mpi"       # build with default MPI Fortran compiler (settings as with "make mpi")
make lib-linalg args="-m gfortran"  # build with GNU Fortran compiler :pre

:line

USER-AWPMD package :h4,link(user-awpmd)

[CMake build]:

No additional settings are needed besides "-D PKG_USER-AQPMD=yes".

[Traditional make]:

Before building LAMMPS, you must build the AWPMD library in lib/awpmd.
You can do this manually if you prefer; follow the instructions in
lib/awpmd/README.  You can also do it in one step from the lammps/src
dir, using a command like these, which simply invoke the
lib/awpmd/Install.py script with the specified args:

make lib-awpmd                   # print help message
make lib-awpmd args="-m serial"  # build with GNU g++ compiler and MPI STUBS (settings as with "make serial")
make lib-awpmd args="-m mpi"     # build with default MPI compiler (settings as with "make mpi")
make lib-awpmd args="-m icc"     # build with Intel icc compiler :pre

The build should produce two files: lib/awpmd/libawpmd.a and
lib/awpmd/Makefile.lammps.  The latter is copied from an existing
Makefile.lammps.* and has settings needed to build LAMMPS with the
AWPMD library.  If necessary, you can edit/create a new
lib/awpmd/Makefile.machine file for your system, which should define
an EXTRAMAKE variable to specify a corresponding
Makefile.lammps.machine file.

Note that the Makefile.lammps file has settings for the BLAS and
LAPACK linear algebra libraries.  As explained in lib/awpmd/README
these can either exist on your system, or you can use the files
provided in lib/linalg.  In the latter case you also need to build the
library in lib/linalg with a command like these:

make lib-linalg                     # print help message
make lib-linalg args="-m serial"    # build with GNU Fortran compiler (settings as with "make serial")
make lib-linalg args="-m mpi"       # build with default MPI Fortran compiler (settings as with "make mpi")
make lib-linalg args="-m gfortran"  # build with GNU Fortran compiler :pre

:line

USER-COLVARS package :h4,link(user-colvars)

This package includes into the LAMMPS distribution the Colvars library, which
can be built for the most part with all major versions of the C++ language.

A few of the most recent features require C++11 support.  In particular, the
library is optionally built together with the
"Lepton"_https://simtk.org/projects/lepton library, a copy of which is also
included in the LAMMPS distribution.  Lepton implements the
"customFunction"_http://colvars.github.io/colvars-refman-lammps/colvars-refman-lammps.html#colvar|customFunction
feature, and requires C++11 support.

See "here"_https://colvars.github.io/README-c++11.html for a detailed list of
C++11-only features.

[CMake build]:

This is the recommended build recipe: no additional settings are normally
needed besides "-D PKG_USER-COLVARS=yes".

Building and linking of Lepton (or other C++11-only features) is enabled
automatically when compilation is carried out with C++11 support, and disabled
otherwise.  Optionally, Lepton build may be manually controlled with the flag
"-D COLVARS_LEPTON=yes|no".

[Traditional make]:

Before building LAMMPS, one must build the Colvars library in lib/colvars.

This can be done manually in the same folder by using or adapting one of the
provided Makefiles: for example, Makefile.g++ for the GNU compiler.

In general, it is safer to use build setting consistent with the rest of
LAMMPS.  This is best carried out from the LAMMPS src directory using a
command like these, which simply invoke the lib/colvars/Install.py script with
the specified args:

make lib-colvars                      # print help message
make lib-colvars args="-m serial"     # build with GNU g++ compiler (settings as with "make serial")
make lib-colvars args="-m mpi"        # build with default MPI compiler (settings as with "make mpi")
make lib-colvars args="-m g++-debug"  # build with GNU g++ compiler and colvars debugging enabled :pre

The "machine" argument of the "-m" flag is used to find a Makefile.machine to
use as build recipe.  If it does not already exist in lib/colvars, it will be
auto-generated by using compiler flags consistent with those parsed from the
core LAMMPS makefiles.

Optional flags may be specified as environment variables:

COLVARS_DEBUG=yes make lib-colvars args="-m machine"  # Build with debug code (much slower)
COLVARS_LEPTON=no make lib-colvars args="-m machine"  # Build without Lepton (included otherwise)

The build should produce two files: the library lib/colvars/libcolvars.a
(which also includes Lepton objects if enabled) and the specification file
lib/colvars/Makefile.lammps.  The latter is auto-generated, and normally does
not need to be edited.


:line

USER-PLUMED package :h4,link(user-plumed)

Before building LAMMPS with this package, you must first build PLUMED.
PLUMED can be built as part of the LAMMPS build or installed separately
from LAMMPS using the generic "plumed installation instructions"_plumedinstall.
:link(plumedinstall,http://plumed.github.io/doc-master/user-doc/html/_installation.html)

PLUMED can be linked into MD codes in three different modes: static,
shared, and runtime.  With the "static" mode, all the code that PLUMED
requires is linked statically into LAMMPS. LAMMPS is then fully
independent from the PLUMED installation, but you have to rebuild/relink
it in order to update the PLUMED code inside it.  With the "shared"
linkage mode, LAMMPS is linked to a shared library that contains the
PLUMED code.  This library should preferably be installed in a globally
accessible location. When PLUMED is linked in this way the same library
can be used by multiple MD packages.  Furthermore, the PLUMED library
LAMMPS uses can be updated without the need for a recompile of LAMMPS
for as long as the shared PLUMED library is ABI-compatible.

The third linkage mode is "runtime" which allows the user to specify
which PLUMED kernel should be used at runtime by using the PLUMED_KERNEL
environment variable. This variable should point to the location of the
libplumedKernel.so dynamical shared object, which is then loaded at
runtime. This mode of linking is particularly convenient for doing
PLUMED development and comparing multiple PLUMED versions as these sorts
of comparisons can be done without recompiling the hosting MD code. All
three linkage modes are supported by LAMMPS on selected operating
systems (e.g. Linux) and using either CMake or traditional make
build. The "static" mode should be the most portable, while the
"runtime" mode support in LAMMPS makes the most assumptions about
operating system and compiler environment. If one mode does not work,
try a different one, switch to a different build system, consider a
global PLUMED installation or consider downloading PLUMED during the
LAMMPS build.

[CMake build]:

When the "-D PKG_USER-PLUMED" flag is included in the cmake command you
must ensure that GSL is installed in locations that are specified in
your environment.  There are then two additional commands that control
the manner in which PLUMED is obtained and linked into LAMMPS.

-D DOWNLOAD_PLUMED=value   # download PLUMED for build, value = no (default) or yes
-D PLUMED_MODE=value       # Linkage mode for PLUMED, value = static (default), shared, or runtime :pre

If DOWNLOAD_PLUMED is set to "yes", the PLUMED library will be
downloaded (the version of PLUMED that will be downloaded is hard-coded
to a vetted version of PLUMED, usually a recent stable release version)
and built inside the CMake build directory.  If DOWNLOAD_PLUMED is set
to "no" (the default), CMake will try to detect and link to an installed
version of PLUMED.  For this to work, the PLUMED library has to be
installed into a location where the pkg-config tool can find it or the
PKG_CONFIG_PATH environment variable has to be set up accordingly.
PLUMED should be installed in such a location if you compile it using
the default make; make install commands.

The PLUMED_MODE setting determines the linkage mode for the PLUMED
library.  The allowed values for this flag are "static" (default),
"shared", or "runtime".  For a discussion of PLUMED linkage modes,
please see above.  When DOWNLOAD_PLUMED is enabled the static linkage
mode is recommended.

[Traditional make]:

PLUMED needs to be installed before the USER-PLUMED package is installed
so that LAMMPS can find the right settings when compiling and linking
the LAMMPS executable.  You can either download and build PLUMED inside
the LAMMPS plumed library folder or use a previously installed PLUMED
library and point LAMMPS to its location. You also have to choose the
linkage mode: "static" (default), "shared" or "runtime".  For a
discussion of PLUMED linkage modes, please see above.

Download/compilation/configuration of the plumed library can be done
from the src folder through the following make args:

make lib-plumed                         # print help message
make lib-plumed args="-b"               # download and build PLUMED in lib/plumed/plumed2
make lib-plumed args="-p $HOME/.local"  # use existing PLUMED installation in $HOME/.local
make lib-plumed args="-p /usr/local -m shared"  # use existing PLUMED installation in
                                                # /usr/local and use shared linkage mode
:pre

Note that 2 symbolic (soft) links, "includelink" and "liblink" are
created in lib/plumed that point to the location of the PLUMED build to
use. A new file lib/plumed/Makefile.lammps is also created with settings
suitable for LAMMPS to compile and link PLUMED using the desired linkage
mode. After this step is completed, you can install the USER-PLUMED
package and compile LAMMPS in the usual manner:

make yes-user-plumed
make machine :pre

Once this compilation completes you should be able to run LAMMPS in the
usual way.  For shared linkage mode, libplumed.so must be found by the
LAMMPS executable, which on many operating systems means, you have to
set the LD_LIBRARY_PATH environment variable accordingly.

Support for the different linkage modes in LAMMPS varies for different
operating systems, using the static linkage is expected to be the most
portable, and thus set to be the default.

If you want to change the linkage mode, you have to re-run "make
lib-plumed" with the desired settings [and] do a re-install if the
USER-PLUMED package with "make yes-user-plumed" to update the required
makefile settings with the changes in the lib/plumed folder.

:line

USER-H5MD package :h4,link(user-h5md)

To build with this package you must have the HDF5 software package
installed on your system, which should include the h5cc compiler and
the HDF5 library.

[CMake build]:

No additional settings are needed besides "-D PKG_USER-H5MD=yes".

This should auto-detect the H5MD library on your system.  Several
advanced CMake H5MD options exist if you need to specify where it is
installed.  Use the ccmake (terminal window) or cmake-gui (graphical)
tools to see these options and set them interactively from their user
interfaces.

[Traditional make]:

Before building LAMMPS, you must build the CH5MD library in lib/h5md.
You can do this manually if you prefer; follow the instructions in
lib/h5md/README.  You can also do it in one step from the lammps/src
dir, using a command like these, which simply invoke the
lib/h5md/Install.py script with the specified args:

make lib-h5md                     # print help message
make lib-h5md args="-m h5cc"      # build with h5cc compiler :pre

The build should produce two files: lib/h5md/libch5md.a and
lib/h5md/Makefile.lammps.  The latter is copied from an existing
Makefile.lammps.* and has settings needed to build LAMMPS with the
system HDF5 library.  If necessary, you can edit/create a new
lib/h5md/Makefile.machine file for your system, which should define an
EXTRAMAKE variable to specify a corresponding Makefile.lammps.machine
file.

:line

USER-INTEL package :h4,link(user-intel)

To build with this package, you must choose which hardware you want to
build for, either x86 CPUs or Intel KNLs in offload mode.  You should
also typically "install the USER-OMP package"_#user-omp, as it can be
used in tandem with the USER-INTEL package to good effect, as explained
on the "Speed intel"_Speed_intel.html doc page.

[CMake build]:

-D INTEL_ARCH=value     # value = cpu (default) or knl
-D INTEL_LRT_MODE=value # value = threads, none, or c++11 :pre

In Long-range thread mode (LRT) a modified verlet style is used, that
operates the Kspace calculation in a separate thread concurrently to
other calculations. This has to be enabled in the "package intel"_package.html
command at runtime. With the setting "threads" it used the pthreads
library, while c++11 will use the built-in thread support of C++11
compilers. The option "none" skips compilation of this feature. The
default is to use "threads" if pthreads is available and otherwise "none".

Best performance is achieved with Intel hardware, Intel compilers, as well as
the Intel TBB and MKL libraries. However, the code also compiles, links, and
runs with other compilers and without TBB and MKL.

[Traditional make]:

Choose which hardware to compile for in Makefile.machine via the
following settings.  See src/MAKE/OPTIONS/Makefile.intel_cpu* and
Makefile.knl files for examples. and src/USER-INTEL/README for
additional information.

For CPUs:

OPTFLAGS =      -xHost -O2 -fp-model fast=2 -no-prec-div -qoverride-limits -qopt-zmm-usage=high
CCFLAGS =       -g -qopenmp -DLAMMPS_MEMALIGN=64 -no-offload -fno-alias -ansi-alias -restrict $(OPTFLAGS)
LINKFLAGS =     -g -qopenmp $(OPTFLAGS)
LIB =           -ltbbmalloc :pre

For KNLs:

OPTFLAGS =      -xMIC-AVX512 -O2 -fp-model fast=2 -no-prec-div -qoverride-limits
CCFLAGS =       -g -qopenmp -DLAMMPS_MEMALIGN=64 -no-offload -fno-alias -ansi-alias -restrict $(OPTFLAGS)
LINKFLAGS =     -g -qopenmp $(OPTFLAGS)
LIB =           -ltbbmalloc :pre

:line

USER-MOLFILE package :h4,link(user-molfile)

[CMake build]:

-D MOLFILE_INCLUDE_DIRS=path   # (optional) path where VMD molfile plugin headers are installed
-D PKG_USER-MOLFILE=yes     :pre


Using "-D PKG_USER-MOLFILE=yes" enables the package, and setting
"-D MOLFILE_INCLUDE DIRS" allows to provide a custom location for
the molfile plugin header files. These should match the ABI of the
plugin files used, and thus one typically sets them to include
folder of the local VMD installation in use. LAMMPS ships with a
couple of default header files that correspond to a popular VMD
version, usually the latest release.

[Traditional make]:

The lib/molfile/Makefile.lammps file has a setting for a dynamic
loading library libdl.a that is typically present on all systems.  It
is required for LAMMPS to link with this package.  If the setting is
not valid for your system, you will need to edit the Makefile.lammps
file.  See lib/molfile/README and lib/molfile/Makefile.lammps for
details. It is also possible to configure a different folder with
the VMD molfile plugin header files. LAMMPS ships with a couple of
default headers, but these are not compatible with all VMD versions,
so it is often best to change this setting to the location of the
same include files of the local VMD installation in use.

:line

USER-NETCDF package :h4,link(user-netcdf)

To build with this package you must have the NetCDF library installed
on your system.

[CMake build]:

No additional settings are needed besides "-D PKG_USER-NETCDF=yes".

This should auto-detect the NETCDF library if it is installed on your
system at standard locations.  Several advanced CMake NETCDF options
exist if you need to specify where it was installed.  Use the ccmake
(terminal window) or cmake-gui (graphical) tools to see these options
and set them interactively from their user interfaces.

[Traditional make]:

The lib/netcdf/Makefile.lammps file has settings for NetCDF include
and library files which LAMMPS needs to build with this package.  If
the settings are not valid for your system, you will need to edit the
Makefile.lammps file.  See lib/netcdf/README for details.

:line

USER-OMP package :h4,link(user-omp)

[CMake build]:

No additional settings are required besides "-D PKG_USER-OMP=yes".  If
CMake detects OpenMP support, the USER-OMP code will be compiled with
multi-threading support enabled, otherwise as optimized serial code.

[Traditional make]:

To enable multi-threading support in the USER-OMP package (and other
styles supporting OpenMP) the following compile and link flags must
be added to your Makefile.machine file.
See src/MAKE/OPTIONS/Makefile.omp for an example.

CCFLAGS: -fopenmp               # for GNU Compilers
CCFLAGS: -qopenmp -restrict     # for Intel compilers on Linux
LINKFLAGS: -fopenmp             # for GNU Compilers
LINKFLAGS: -qopenmp             # for Intel compilers on Linux :pre

For other platforms and compilers, please consult the documentation
about OpenMP support for your compiler. Please see the note about
how to address compatibility "issues with the 'default(none)'
directive"_Build_basics.html#default-none-issues of some compilers.

:line

USER-QMMM package :h4,link(user-qmmm)

NOTE: The LAMMPS executable these steps produce is not yet functional
for a QM/MM simulation.  You must also build Quantum ESPRESSO and
create a new executable (pwqmmm.x) which links LAMMPS and Quantum
ESPRESSO together.  These are steps 3 and 4 described in the
lib/qmmm/README file.  Unfortunately, the Quantum ESPRESSO developers
have been breaking the interface that the QM/MM code in LAMMPS is using,
so that currently (Summer 2018) using this feature requires either
correcting the library interface feature in recent Quantum ESPRESSO
releases, or using an outdated version of QE. The last version of
Quantum ESPRESSO known to work with this QM/MM interface was version
5.4.1 from 2016.

[CMake build]:

The CMake build system currently does not support building the full
QM/MM-capable hybrid executable of LAMMPS and QE called pwqmmm.x.
You must use the traditional make build for this package.

[Traditional make]:

Before building LAMMPS, you must build the QMMM library in lib/qmmm.
You can do this manually if you prefer; follow the first two steps
explained in lib/qmmm/README.  You can also do it in one step from the
lammps/src dir, using a command like these, which simply invoke the
lib/qmmm/Install.py script with the specified args:

make lib-qmmm                      # print help message
make lib-qmmm args="-m serial"     # build with GNU Fortran compiler (settings as in "make serial")
make lib-qmmm args="-m mpi"        # build with default MPI compiler (settings as in "make mpi")
make lib-qmmm args="-m gfortran"   # build with GNU Fortran compiler :pre

The build should produce two files: lib/qmmm/libqmmm.a and
lib/qmmm/Makefile.lammps.  The latter is copied from an existing
Makefile.lammps.* and has settings needed to build LAMMPS with the
QMMM library (though typically the settings are just blank).  If
necessary, you can edit/create a new lib/qmmm/Makefile.machine file
for your system, which should define an EXTRAMAKE variable to specify
a corresponding Makefile.lammps.machine file.

You can then install QMMM package and build LAMMPS in the usual
manner.  After completing the LAMMPS build and compiling Quantum
ESPRESSO with external library support, go back to the lib/qmmm folder
and follow the instructions on the README file to build the combined
LAMMPS/QE QM/MM executable (pwqmmm.x) in the lib/qmmm folder.

:line

USER-QUIP package :h4,link(user-quip)

To build with this package, you must download and build the QUIP
library.  It can be obtained from GitHub.  For support of GAP
potentials, additional files with specific licensing conditions need
to be downloaded and configured.  See step 1 and step 1.1 in the
lib/quip/README file for details on how to do this.

[CMake build]:

-D QUIP_LIBRARY=path     # path to libquip.a (only needed if a custom location) :pre

CMake will not download and build the QUIP library.  But once you have
done that, a CMake build of LAMMPS with "-D PKG_USER-QUIP=yes" should
work.  Set QUIP_LIBRARY if CMake cannot find the QUIP library.

[Traditional make]:

The download/build procedure for the QUIP library, described in
lib/quip/README file requires setting two environment variables,
QUIP_ROOT and QUIP_ARCH.  These are accessed by the
lib/quip/Makefile.lammps file which is used when you compile and link
LAMMPS with this package.  You should only need to edit
Makefile.lammps if the LAMMPS build can not use its settings to
successfully build on your system.

:line

USER-SCAFACOS package :h4,link(user-scafacos)

To build with this package, you must download and build the "ScaFaCoS
Coulomb solver library"_scafacos-home

:link(scafacos-home,http://www.scafacos.de)

[CMake build]:

-D DOWNLOAD_SCAFACOS=value    # download ScaFaCoS for build, value = no (default) or yes
-D SCAFACOS_LIBRARY=path      # ScaFaCos library file (only needed if at custom location)
-D SCAFACOS_INCLUDE_DIR=path  # ScaFaCoS include directory (only needed if at custom location) :pre

If DOWNLOAD_SCAFACOS is set, the ScaFaCoS library will be downloaded
and built inside the CMake build directory.  If the ScaFaCoS library
is already on your system (in a location CMake cannot find it),
SCAFACOS_LIBRARY is the filename (plus path) of the ScaFaCoS library
file, not the directory the library file is in.  SCAFACOS_INCLUDE_DIR
is the directory the ScaFaCoS include file is in.

[Traditional make]:

You can download and build the ScaFaCoS library manually if you
prefer; follow the instructions in lib/scafacos/README.  You can also
do it in one step from the lammps/src dir, using a command like these,
which simply invoke the lib/scafacos/Install.py script with the
specified args:

make lib-scafacos                         # print help message
make lib-scafacos args="-b"               # download and build in lib/scafacos/scafacos-<version>
make lib-scafacos args="-p $HOME/scafacos  # use existing ScaFaCoS installation in $HOME/scafacos

Note that 2 symbolic (soft) links, "includelink" and "liblink", are
created in lib/scafacos to point to the ScaFaCoS src dir.  When LAMMPS
builds in src it will use these links.  You should not need to edit
the lib/scafacos/Makefile.lammps file.

:line

USER-SMD package :h4,link(user-smd)

To build with this package, you must download the Eigen3 library.
Eigen3 is a template library, so you do not need to build it.

[CMake build]:

-D DOWNLOAD_EIGEN3            # download Eigen3, value = no (default) or yes
-D EIGEN3_INCLUDE_DIR=path    # path to Eigen library (only needed if a custom location) :pre

If DOWNLOAD_EIGEN3 is set, the Eigen3 library will be downloaded and
inside the CMake build directory.  If the Eigen3 library is already on
your system (in a location CMake cannot find it), EIGEN3_INCLUDE_DIR
is the directory the Eigen3++ include file is in.

[Traditional make]:

You can download the Eigen3 library manually if you prefer; follow the
instructions in lib/smd/README.  You can also do it in one step from
the lammps/src dir, using a command like these, which simply invoke
the lib/smd/Install.py script with the specified args:

make lib-smd                         # print help message
make lib-smd args="-b"               # download to lib/smd/eigen3
make lib-smd args="-p /usr/include/eigen3"    # use existing Eigen installation in /usr/include/eigen3 :pre

Note that a symbolic (soft) link named "includelink" is created in
lib/smd to point to the Eigen dir.  When LAMMPS builds it will use
this link.  You should not need to edit the lib/smd/Makefile.lammps
file.

:line

USER-VTK package :h4,link(user-vtk)

To build with this package you must have the VTK library installed on
your system.

[CMake build]:

No additional settings are needed besides "-D PKG_USER-VTK=yes".

This should auto-detect the VTK library if it is installed on your
system at standard locations.  Several advanced VTK options exist if
you need to specify where it was installed.  Use the ccmake (terminal
window) or cmake-gui (graphical) tools to see these options and set
them interactively from their user interfaces.

[Traditional make]:

The lib/vtk/Makefile.lammps file has settings for accessing VTK files
and its library, which LAMMPS needs to build with this package.  If
the settings are not valid for your system, check if one of the other
lib/vtk/Makefile.lammps.* files is compatible and copy it to
Makefile.lammps.  If none of the provided files work, you will need to
edit the Makefile.lammps file.  See lib/vtk/README for details.
